{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello tensorflow\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import numpy as np\n",
    "import os\n",
    "import shutil\n",
    "import sklearn\n",
    "import cv2\n",
    "import csv\n",
    "import math\n",
    "#import image\n",
    "from skimage.io import imread\n",
    "from PIL import Image\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "import matplotlib.image as mpimg\n",
    "#导入图表库\n",
    "import matplotlib.pyplot as plt\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras import applications\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg19 import VGG19\n",
    "\n",
    "from keras.applications.vgg19 import preprocess_input\n",
    "\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import preprocessing   \n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from keras.utils import plot_model\n",
    "# PCA 主成分分析\n",
    "from sklearn.decomposition import PCA\n",
    "from keras.callbacks import TensorBoard\n",
    "print(\"hello tensorflow\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 读取数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(239999, 1024)\n",
      "[[0.31910929 0.52602024 0.47184321 ... 0.39789196 0.36649874 0.35365854]\n",
      " [0.31910929 0.52602024 0.47184321 ... 0.08695652 0.08312343 0.0804878 ]\n",
      " [0.31910929 0.52602024 0.47184321 ... 0.39262187 0.395466   0.39878049]\n",
      " ...\n",
      " [0.64525379 0.91699595 0.65415632 ... 0.47694335 0.59823678 0.60487805]\n",
      " [0.55993044 0.40413241 0.47403153 ... 0.75625824 0.69269521 0.59512195]\n",
      " [0.64658885 0.30753055 0.35559861 ... 0.50988142 0.5302267  0.47560976]]\n"
     ]
    }
   ],
   "source": [
    "# 读取数据\n",
    "X = pd.read_csv(open(\"../../emotionData/finalData.csv\",encoding='utf-8'))\n",
    "#X = pd.DataFrame(X)\n",
    "X = X[0:239999]\n",
    "X = X.values\n",
    "\n",
    "print(X.shape)\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(239999, 1)\n",
      "               0\n",
      "0       0.136147\n",
      "1       0.058372\n",
      "2       0.126422\n",
      "3       0.108744\n",
      "4       0.110896\n",
      "5        0.17498\n",
      "6       0.134798\n",
      "7       0.133093\n",
      "8       0.114068\n",
      "9        0.08394\n",
      "10      0.138001\n",
      "11      0.162281\n",
      "12      0.024871\n",
      "13      0.049312\n",
      "14      0.074712\n",
      "15      0.027434\n",
      "16      0.127124\n",
      "17      0.051743\n",
      "18      0.084803\n",
      "19        0.0248\n",
      "20      0.105067\n",
      "21      0.141144\n",
      "22       0.08615\n",
      "23      0.135191\n",
      "24      0.152599\n",
      "25      0.168492\n",
      "26      0.074377\n",
      "27      0.190048\n",
      "28       0.03048\n",
      "29      0.059181\n",
      "...          ...\n",
      "239969  0.057701\n",
      "239970    0.0552\n",
      "239971  0.081782\n",
      "239972  0.071156\n",
      "239973  0.058882\n",
      "239974  0.074815\n",
      "239975  0.113112\n",
      "239976  0.050515\n",
      "239977  0.144805\n",
      "239978  0.125566\n",
      "239979  0.127759\n",
      "239980  0.143141\n",
      "239981   0.10808\n",
      "239982  0.099706\n",
      "239983  0.124837\n",
      "239984  0.119256\n",
      "239985  0.093946\n",
      "239986   0.09057\n",
      "239987   0.14971\n",
      "239988  0.136218\n",
      "239989  0.102945\n",
      "239990  0.127501\n",
      "239991  0.071766\n",
      "239992  0.073368\n",
      "239993  0.144539\n",
      "239994  0.101104\n",
      "239995  0.105414\n",
      "239996  0.118857\n",
      "239997  0.063416\n",
      "239998  0.067812\n",
      "\n",
      "[239999 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "with open('../../emotionData/s25w-r-n.CSV',\"rt\", encoding=\"utf-8\") as vsvfile:\n",
    "    reader = csv.reader(vsvfile)\n",
    "    y = [row[128] for row in reader]\n",
    "#y = pd.DataFrame(y)\n",
    "y = y[1:]\n",
    "y = y[0:239999]\n",
    "#\n",
    "y = pd.DataFrame(y)\n",
    "print(y.shape)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers.normalization import BatchNormalization\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(1024, input_dim=1024, activation='relu'))\n",
    "model.add(keras.layers.normalization.BatchNormalization(axis=-1, \n",
    "                                              momentum=0.99, \n",
    "                                              epsilon=0.001, \n",
    "                                              center=True, \n",
    "                                              scale=True, \n",
    "                                              beta_initializer='zeros', \n",
    "                                              gamma_initializer='ones',\n",
    "                                              ))\n",
    "\n",
    "model.add(Dense(1024, input_dim=1024, activation='relu'))\n",
    "model.add(keras.layers.normalization.BatchNormalization(axis=-1, \n",
    "                                              momentum=0.99, \n",
    "                                              epsilon=0.001, \n",
    "                                              center=True, \n",
    "                                              scale=True, \n",
    "                                              beta_initializer='zeros', \n",
    "                                              gamma_initializer='ones',\n",
    "                                              ))\n",
    "\n",
    "\n",
    "model.add(Dense(512, input_dim=1024, activation='relu'))\n",
    "model.add(keras.layers.normalization.BatchNormalization(axis=-1, \n",
    "                                              momentum=0.99, \n",
    "                                              epsilon=0.001, \n",
    "                                              center=True, \n",
    "                                              scale=True, \n",
    "                                              beta_initializer='zeros', \n",
    "                                              gamma_initializer='ones',\n",
    "                                              ))\n",
    "\n",
    "model.add(Dense(512, input_dim=512, activation='relu'))\n",
    "model.add(keras.layers.normalization.BatchNormalization(axis=-1, \n",
    "                                              momentum=0.99, \n",
    "                                              epsilon=0.001, \n",
    "                                              center=True, \n",
    "                                              scale=True, \n",
    "                                              beta_initializer='zeros', \n",
    "                                              gamma_initializer='ones',\n",
    "                                              ))\n",
    "\n",
    "model.add(Dense(256, input_dim=512, activation='relu'))\n",
    "model.add(keras.layers.normalization.BatchNormalization(axis=-1, \n",
    "                                              momentum=0.99, \n",
    "                                              epsilon=0.001, \n",
    "                                              center=True, \n",
    "                                              scale=True, \n",
    "                                              beta_initializer='zeros', \n",
    "                                              gamma_initializer='ones',\n",
    "                                              ))\n",
    "\n",
    "model.add(Dense(256, input_dim=256, activation='relu'))\n",
    "model.add(keras.layers.normalization.BatchNormalization(axis=-1, \n",
    "                                              momentum=0.99, \n",
    "                                              epsilon=0.001, \n",
    "                                              center=True, \n",
    "                                              scale=True, \n",
    "                                              beta_initializer='zeros', \n",
    "                                              gamma_initializer='ones',\n",
    "                                              ))\n",
    "\n",
    "model.add(Dense(128, input_dim=256, activation='relu'))\n",
    "model.add(keras.layers.normalization.BatchNormalization(axis=-1, \n",
    "                                              momentum=0.99, \n",
    "                                              epsilon=0.001, \n",
    "                                              center=True, \n",
    "                                              scale=True, \n",
    "                                              beta_initializer='zeros', \n",
    "                                              gamma_initializer='ones',\n",
    "                                              ))\n",
    "\n",
    "model.add(Dense(128, input_dim=128, activation='relu'))\n",
    "model.add(keras.layers.normalization.BatchNormalization(axis=-1, \n",
    "                                              momentum=0.99, \n",
    "                                              epsilon=0.001, \n",
    "                                              center=True, \n",
    "                                              scale=True, \n",
    "                                              beta_initializer='zeros', \n",
    "                                              gamma_initializer='ones',\n",
    "                                              ))\n",
    "\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(keras.layers.normalization.BatchNormalization(axis=-1, \n",
    "                                              momentum=0.99, \n",
    "                                              epsilon=0.001, \n",
    "                                              center=True, \n",
    "                                              scale=True, \n",
    "                                              beta_initializer='zeros', \n",
    "                                              gamma_initializer='ones',\n",
    "                                              ))\n",
    "\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(keras.layers.normalization.BatchNormalization(axis=-1, \n",
    "                                              momentum=0.99, \n",
    "                                              epsilon=0.001, \n",
    "                                              center=True, \n",
    "                                              scale=True, \n",
    "                                              beta_initializer='zeros', \n",
    "                                              gamma_initializer='ones',\n",
    "                                              ))\n",
    "\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(keras.layers.normalization.BatchNormalization(axis=-1, \n",
    "                                              momentum=0.99, \n",
    "                                              epsilon=0.001, \n",
    "                                              center=True, \n",
    "                                              scale=True, \n",
    "                                              beta_initializer='zeros', \n",
    "                                              gamma_initializer='ones',\n",
    "                                              ))\n",
    "\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(keras.layers.normalization.BatchNormalization(axis=-1, \n",
    "                                              momentum=0.99, \n",
    "                                              epsilon=0.001, \n",
    "                                              center=True, \n",
    "                                              scale=True, \n",
    "                                              beta_initializer='zeros', \n",
    "                                              gamma_initializer='ones',\n",
    "                                              ))\n",
    "\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(keras.layers.normalization.BatchNormalization(axis=-1, \n",
    "                                              momentum=0.99, \n",
    "                                              epsilon=0.001, \n",
    "                                              center=True, \n",
    "                                              scale=True, \n",
    "                                              beta_initializer='zeros', \n",
    "                                              gamma_initializer='ones',\n",
    "                                              ))\n",
    "\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(keras.layers.normalization.BatchNormalization(axis=-1, \n",
    "                                              momentum=0.99, \n",
    "                                              epsilon=0.001, \n",
    "                                              center=True, \n",
    "                                              scale=True, \n",
    "                                              beta_initializer='zeros', \n",
    "                                              gamma_initializer='ones',\n",
    "                                              ))\n",
    "\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(keras.layers.normalization.BatchNormalization(axis=-1, \n",
    "                                              momentum=0.99, \n",
    "                                              epsilon=0.001, \n",
    "                                              center=True, \n",
    "                                              scale=True, \n",
    "                                              beta_initializer='zeros', \n",
    "                                              gamma_initializer='ones',\n",
    "                                              ))\n",
    "\n",
    "\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "def mre(y_true, y_pred):\n",
    "    return K.mean(K.sum(K.abs(100*K.ones_like(y_true) * (y_true - y_pred) / y_true)))\n",
    "\n",
    "\n",
    "def pearson_r(y_true, y_pred):\n",
    "    x = y_true\n",
    "    y = y_pred\n",
    "    mx = K.mean(x, axis=0)\n",
    "    my = K.mean(y, axis=0)\n",
    "    xm, ym = x - mx, y - my\n",
    "    r_num = K.sum(xm * ym)\n",
    "    x_square_sum = K.sum(xm * xm)\n",
    "    y_square_sum = K.sum(ym * ym)\n",
    "    r_den = K.sqrt(x_square_sum * y_square_sum)\n",
    "    r = r_num / r_den\n",
    "    return K.mean(r)\n",
    "\n",
    "def r_square_final(y_true, y_pred):\n",
    "    SSR = K.mean(K.square(y_pred-K.mean(y_true)),axis=-1)\n",
    "    SST = K.mean(K.square(y_true-K.mean(y_true)),axis=-1)\n",
    "    return SSR/SST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 16)                64        \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 16)                64        \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 8)                 32        \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "batch_normalization_15 (Batc (None, 8)                 32        \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 3,164,889\n",
      "Trainable params: 3,156,793\n",
      "Non-trainable params: 8,096\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model.compile(\n",
    "    loss='mean_squared_error', \n",
    "    optimizer='adam',\n",
    "    metrics=['mean_squared_error',\n",
    "             'mean_absolute_error',\n",
    "             'mean_absolute_percentage_error',\n",
    "             'mean_squared_logarithmic_error',\n",
    "             r_square_final,\n",
    "            # metrics.r2_score,\n",
    "            # metrics.r2_score,\n",
    "             pearson_r,\n",
    "             mre]\n",
    ")\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks_list = [\n",
    "    # 训练可视化\n",
    "    keras.callbacks.TensorBoard(\n",
    "        log_dir='./fit_Euclidean_Distance_logs',  # log 目录\n",
    "        histogram_freq=0,  # 按照何等频率（epoch）来计算直方图，0为不计算\n",
    "        #batch_size=32,     # 用多大量的数据计算直方图\n",
    "        write_graph=True,  # 是否存储网络结构图\n",
    "        write_grads=True, # 是否可视化梯度直方图\n",
    "        write_images=True,# 是否可视化参数\n",
    "        embeddings_freq=0,\n",
    "        embeddings_layer_names=None, \n",
    "        embeddings_metadata=None),\n",
    "    \n",
    "    # 训练自动更改学习率\n",
    "    keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor='val_mean_squared_error', \n",
    "        factor=0.2,\n",
    "        patience=5,\n",
    "        verbose=1,\n",
    "        mode='min',\n",
    "        min_delta=0.0001, \n",
    "        cooldown=0, \n",
    "        min_lr=0.0001),\n",
    "    \n",
    "    # 当被监测的数量不再提升，则停止训练\n",
    "    keras.callbacks.EarlyStopping(\n",
    "        monitor='val_mean_squared_error', \n",
    "        min_delta=0, \n",
    "        patience=30, \n",
    "        verbose=1, \n",
    "        mode='min', \n",
    "        baseline=None, \n",
    "        restore_best_weights=False)\n",
    "\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.backend.tensorflow_backend as KTF #进行配置，每个GPU使用80%上限现存\n",
    "\n",
    "\n",
    "#os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"  # 使用编号为0号的GPU\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.8 # 每个GPU现存上届控制在80%以内\n",
    "session = tf.Session(config=config) # 设置session KTF.set_session(session )\n",
    "#设置session\n",
    "KTF.set_session(session )\n",
    "\n",
    "#注意：\n",
    "#config.gpu_options.per_process_gpu_memory_fraction = 0.8 # 每个GPU现存上届控制在80%以内\n",
    "#设置GPU使用上限，可以有效避免显存不足而导致的jupyter 问题:\n",
    "#The kernel appears to have died. It will restart automatically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 215999 samples, validate on 24000 samples\n",
      "Epoch 1/70\n",
      "215999/215999 [==============================] - 49s 228us/step - loss: 0.0717 - mean_squared_error: 0.0717 - mean_absolute_error: 0.2337 - mean_absolute_percentage_error: 1374.4046 - mean_squared_logarithmic_error: 0.0436 - r_square_final: 3257622.9715 - pearson_r: 0.0011 - mre: inf - val_loss: 0.0196 - val_mean_squared_error: 0.0196 - val_mean_absolute_error: 0.1077 - val_mean_absolute_percentage_error: 127.2291 - val_mean_squared_logarithmic_error: 0.0122 - val_r_square_final: 155431989.2690 - val_pearson_r: 0.0038 - val_mre: 129137.2310\n",
      "Epoch 2/70\n",
      "215999/215999 [==============================] - 45s 210us/step - loss: 0.0136 - mean_squared_error: 0.0136 - mean_absolute_error: 0.0709 - mean_absolute_percentage_error: 933.3313 - mean_squared_logarithmic_error: 0.0077 - r_square_final: 2850470.4360 - pearson_r: 0.0024 - mre: inf - val_loss: 0.0108 - val_mean_squared_error: 0.0108 - val_mean_absolute_error: 0.0491 - val_mean_absolute_percentage_error: 61.3530 - val_mean_squared_logarithmic_error: 0.0056 - val_r_square_final: 3998363.1494 - val_pearson_r: 0.0055 - val_mre: 62346.4812\n",
      "Epoch 3/70\n",
      "215999/215999 [==============================] - 45s 207us/step - loss: 0.0103 - mean_squared_error: 0.0103 - mean_absolute_error: 0.0419 - mean_absolute_percentage_error: 657.9105 - mean_squared_logarithmic_error: 0.0051 - r_square_final: 4240379.9994 - pearson_r: 0.0018 - mre: inf - val_loss: 0.0098 - val_mean_squared_error: 0.0098 - val_mean_absolute_error: 0.0378 - val_mean_absolute_percentage_error: 46.5192 - val_mean_squared_logarithmic_error: 0.0048 - val_r_square_final: 5046191.0633 - val_pearson_r: 0.0029 - val_mre: 47280.0715\n",
      "Epoch 4/70\n",
      "215999/215999 [==============================] - 44s 205us/step - loss: 0.0101 - mean_squared_error: 0.0101 - mean_absolute_error: 0.0383 - mean_absolute_percentage_error: 550.5679 - mean_squared_logarithmic_error: 0.0049 - r_square_final: 84602.5994 - pearson_r: 0.0017 - mre: inf - val_loss: 0.0096 - val_mean_squared_error: 0.0096 - val_mean_absolute_error: 0.0358 - val_mean_absolute_percentage_error: 43.3497 - val_mean_squared_logarithmic_error: 0.0046 - val_r_square_final: 2233985.6713 - val_pearson_r: 0.0046 - val_mre: 44065.4480\n",
      "Epoch 5/70\n",
      "215999/215999 [==============================] - 49s 225us/step - loss: 0.0101 - mean_squared_error: 0.0101 - mean_absolute_error: 0.0379 - mean_absolute_percentage_error: 559.2616 - mean_squared_logarithmic_error: 0.0049 - r_square_final: 43150.0616 - pearson_r: 0.0026 - mre: inf - val_loss: 0.0095 - val_mean_squared_error: 0.0095 - val_mean_absolute_error: 0.0349 - val_mean_absolute_percentage_error: 41.7697 - val_mean_squared_logarithmic_error: 0.0046 - val_r_square_final: 3572380.4127 - val_pearson_r: 0.0035 - val_mre: 42458.2872\n",
      "Epoch 6/70\n",
      "215999/215999 [==============================] - 52s 239us/step - loss: 0.0101 - mean_squared_error: 0.0101 - mean_absolute_error: 0.0379 - mean_absolute_percentage_error: 566.2762 - mean_squared_logarithmic_error: 0.0049 - r_square_final: 152663.8822 - pearson_r: 0.0027 - mre: inf - val_loss: 0.0095 - val_mean_squared_error: 0.0095 - val_mean_absolute_error: 0.0346 - val_mean_absolute_percentage_error: 41.2199 - val_mean_squared_logarithmic_error: 0.0046 - val_r_square_final: 3079334.1837 - val_pearson_r: 0.0025 - val_mre: 41896.5835\n",
      "Epoch 7/70\n",
      "215999/215999 [==============================] - 52s 240us/step - loss: 0.0100 - mean_squared_error: 0.0100 - mean_absolute_error: 0.0377 - mean_absolute_percentage_error: 573.5576 - mean_squared_logarithmic_error: 0.0049 - r_square_final: 5571.9753 - pearson_r: 0.0023 - mre: inf - val_loss: 0.0095 - val_mean_squared_error: 0.0095 - val_mean_absolute_error: 0.0349 - val_mean_absolute_percentage_error: 41.8109 - val_mean_squared_logarithmic_error: 0.0046 - val_r_square_final: 1650840.5084 - val_pearson_r: 0.0046 - val_mre: 42500.3091\n",
      "Epoch 8/70\n",
      "215999/215999 [==============================] - 55s 257us/step - loss: 0.0097 - mean_squared_error: 0.0097 - mean_absolute_error: 0.0383 - mean_absolute_percentage_error: 620.4742 - mean_squared_logarithmic_error: 0.0048 - r_square_final: 27561.4358 - pearson_r: 0.0021 - mre: inf - val_loss: 0.0112 - val_mean_squared_error: 0.0112 - val_mean_absolute_error: 0.0511 - val_mean_absolute_percentage_error: 55.8977 - val_mean_squared_logarithmic_error: 0.0063 - val_r_square_final: 1352680.8312 - val_pearson_r: -0.0114 - val_mre: 56601.8806\n",
      "Epoch 9/70\n",
      "215999/215999 [==============================] - 59s 272us/step - loss: 0.0071 - mean_squared_error: 0.0071 - mean_absolute_error: 0.0395 - mean_absolute_percentage_error: 573.0371 - mean_squared_logarithmic_error: 0.0039 - r_square_final: 107404.5852 - pearson_r: -0.0031 - mre: inf - val_loss: 0.0020 - val_mean_squared_error: 0.0020 - val_mean_absolute_error: 0.0358 - val_mean_absolute_percentage_error: 40.7603 - val_mean_squared_logarithmic_error: 0.0016 - val_r_square_final: 10715830.3365 - val_pearson_r: 0.0150 - val_mre: 41317.8964\n",
      "Epoch 10/70\n",
      "215999/215999 [==============================] - 58s 270us/step - loss: 0.0038 - mean_squared_error: 0.0038 - mean_absolute_error: 0.0307 - mean_absolute_percentage_error: 589.7979 - mean_squared_logarithmic_error: 0.0022 - r_square_final: 6201.8947 - pearson_r: 1.9941e-04 - mre: inf - val_loss: 9.9922e-04 - val_mean_squared_error: 9.9922e-04 - val_mean_absolute_error: 0.0258 - val_mean_absolute_percentage_error: 30.7818 - val_mean_squared_logarithmic_error: 8.2373e-04 - val_r_square_final: 3582549.0193 - val_pearson_r: 0.0022 - val_mre: 31215.3044\n",
      "Epoch 11/70\n",
      "215999/215999 [==============================] - 58s 271us/step - loss: 0.0038 - mean_squared_error: 0.0038 - mean_absolute_error: 0.0306 - mean_absolute_percentage_error: 554.6597 - mean_squared_logarithmic_error: 0.0022 - r_square_final: 4671.4482 - pearson_r: 0.0055 - mre: inf - val_loss: 9.5922e-04 - val_mean_squared_error: 9.5922e-04 - val_mean_absolute_error: 0.0255 - val_mean_absolute_percentage_error: 31.5178 - val_mean_squared_logarithmic_error: 7.9296e-04 - val_r_square_final: 2509057.5773 - val_pearson_r: 0.0074 - val_mre: 31966.8154\n",
      "Epoch 12/70\n",
      "215999/215999 [==============================] - 59s 272us/step - loss: 0.0038 - mean_squared_error: 0.0038 - mean_absolute_error: 0.0305 - mean_absolute_percentage_error: 565.9302 - mean_squared_logarithmic_error: 0.0022 - r_square_final: 1521.1829 - pearson_r: 0.0040 - mre: inf - val_loss: 9.6628e-04 - val_mean_squared_error: 9.6628e-04 - val_mean_absolute_error: 0.0256 - val_mean_absolute_percentage_error: 31.7466 - val_mean_squared_logarithmic_error: 7.9899e-04 - val_r_square_final: 2511601.1075 - val_pearson_r: 1.6116e-05 - val_mre: 32194.2075\n",
      "Epoch 13/70\n",
      "215999/215999 [==============================] - 58s 270us/step - loss: 0.0038 - mean_squared_error: 0.0038 - mean_absolute_error: 0.0305 - mean_absolute_percentage_error: 506.9536 - mean_squared_logarithmic_error: 0.0022 - r_square_final: 2721.5832 - pearson_r: 0.0052 - mre: inf - val_loss: 9.8042e-04 - val_mean_squared_error: 9.8042e-04 - val_mean_absolute_error: 0.0258 - val_mean_absolute_percentage_error: 32.1862 - val_mean_squared_logarithmic_error: 8.1098e-04 - val_r_square_final: 2440144.6559 - val_pearson_r: 0.0090 - val_mre: 32640.8098\n",
      "Epoch 14/70\n",
      "215999/215999 [==============================] - 59s 271us/step - loss: 0.0038 - mean_squared_error: 0.0038 - mean_absolute_error: 0.0305 - mean_absolute_percentage_error: 537.5230 - mean_squared_logarithmic_error: 0.0022 - r_square_final: 7068.8309 - pearson_r: 0.0033 - mre: inf - val_loss: 9.8834e-04 - val_mean_squared_error: 9.8834e-04 - val_mean_absolute_error: 0.0259 - val_mean_absolute_percentage_error: 32.2599 - val_mean_squared_logarithmic_error: 8.1794e-04 - val_r_square_final: 3281766.8625 - val_pearson_r: -0.0022 - val_mre: 32715.5605\n",
      "Epoch 15/70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "215999/215999 [==============================] - 58s 268us/step - loss: 0.0038 - mean_squared_error: 0.0038 - mean_absolute_error: 0.0305 - mean_absolute_percentage_error: 547.3598 - mean_squared_logarithmic_error: 0.0022 - r_square_final: 1025.2936 - pearson_r: 0.0016 - mre: inf - val_loss: 9.6808e-04 - val_mean_squared_error: 9.6808e-04 - val_mean_absolute_error: 0.0256 - val_mean_absolute_percentage_error: 31.8819 - val_mean_squared_logarithmic_error: 8.0073e-04 - val_r_square_final: 2293671.2011 - val_pearson_r: 0.0017 - val_mre: 32332.4173\n",
      "\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "Epoch 16/70\n",
      "215999/215999 [==============================] - 58s 270us/step - loss: 0.0038 - mean_squared_error: 0.0038 - mean_absolute_error: 0.0304 - mean_absolute_percentage_error: 532.0457 - mean_squared_logarithmic_error: 0.0021 - r_square_final: 699.1226 - pearson_r: 0.0052 - mre: inf - val_loss: 9.6731e-04 - val_mean_squared_error: 9.6731e-04 - val_mean_absolute_error: 0.0256 - val_mean_absolute_percentage_error: 31.8863 - val_mean_squared_logarithmic_error: 8.0013e-04 - val_r_square_final: 2402561.4750 - val_pearson_r: -0.0024 - val_mre: 32337.0726\n",
      "Epoch 17/70\n",
      "215999/215999 [==============================] - 58s 269us/step - loss: 0.0038 - mean_squared_error: 0.0038 - mean_absolute_error: 0.0304 - mean_absolute_percentage_error: 557.6707 - mean_squared_logarithmic_error: 0.0021 - r_square_final: 329.3357 - pearson_r: 0.0044 - mre: inf - val_loss: 9.6562e-04 - val_mean_squared_error: 9.6562e-04 - val_mean_absolute_error: 0.0256 - val_mean_absolute_percentage_error: 31.8437 - val_mean_squared_logarithmic_error: 7.9867e-04 - val_r_square_final: 2431488.9628 - val_pearson_r: 3.3521e-04 - val_mre: 32293.3481\n",
      "Epoch 18/70\n",
      "215999/215999 [==============================] - 59s 273us/step - loss: 0.0038 - mean_squared_error: 0.0038 - mean_absolute_error: 0.0304 - mean_absolute_percentage_error: 528.7394 - mean_squared_logarithmic_error: 0.0021 - r_square_final: 430.8405 - pearson_r: 0.0059 - mre: inf - val_loss: 9.6800e-04 - val_mean_squared_error: 9.6800e-04 - val_mean_absolute_error: 0.0257 - val_mean_absolute_percentage_error: 31.9137 - val_mean_squared_logarithmic_error: 8.0067e-04 - val_r_square_final: 2490030.7457 - val_pearson_r: -0.0060 - val_mre: 32366.0577\n",
      "Epoch 19/70\n",
      "215999/215999 [==============================] - 58s 270us/step - loss: 0.0038 - mean_squared_error: 0.0038 - mean_absolute_error: 0.0304 - mean_absolute_percentage_error: 529.8365 - mean_squared_logarithmic_error: 0.0021 - r_square_final: 487.2136 - pearson_r: 0.0085 - mre: inf - val_loss: 9.5950e-04 - val_mean_squared_error: 9.5950e-04 - val_mean_absolute_error: 0.0255 - val_mean_absolute_percentage_error: 31.6825 - val_mean_squared_logarithmic_error: 7.9348e-04 - val_r_square_final: 2399279.0969 - val_pearson_r: -0.0055 - val_mre: 32130.0884\n",
      "Epoch 20/70\n",
      "215999/215999 [==============================] - 58s 270us/step - loss: 0.0038 - mean_squared_error: 0.0038 - mean_absolute_error: 0.0304 - mean_absolute_percentage_error: 491.3953 - mean_squared_logarithmic_error: 0.0021 - r_square_final: 287992.8833 - pearson_r: 0.0037 - mre: inf - val_loss: 9.6112e-04 - val_mean_squared_error: 9.6112e-04 - val_mean_absolute_error: 0.0256 - val_mean_absolute_percentage_error: 31.7455 - val_mean_squared_logarithmic_error: 7.9487e-04 - val_r_square_final: 2408301.0787 - val_pearson_r: -0.0059 - val_mre: 32194.7291\n",
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 0.0001.\n",
      "Epoch 21/70\n",
      "215999/215999 [==============================] - 58s 269us/step - loss: 0.0038 - mean_squared_error: 0.0038 - mean_absolute_error: 0.0304 - mean_absolute_percentage_error: 529.7788 - mean_squared_logarithmic_error: 0.0021 - r_square_final: 625.6455 - pearson_r: 0.0078 - mre: inf - val_loss: 9.6195e-04 - val_mean_squared_error: 9.6195e-04 - val_mean_absolute_error: 0.0256 - val_mean_absolute_percentage_error: 31.7796 - val_mean_squared_logarithmic_error: 7.9560e-04 - val_r_square_final: 2412006.8093 - val_pearson_r: -0.0020 - val_mre: 32229.6166\n",
      "Epoch 22/70\n",
      "215999/215999 [==============================] - 58s 268us/step - loss: 0.0038 - mean_squared_error: 0.0038 - mean_absolute_error: 0.0304 - mean_absolute_percentage_error: 589.5021 - mean_squared_logarithmic_error: 0.0021 - r_square_final: 292.2939 - pearson_r: 0.0066 - mre: inf - val_loss: 9.5959e-04 - val_mean_squared_error: 9.5959e-04 - val_mean_absolute_error: 0.0255 - val_mean_absolute_percentage_error: 31.7241 - val_mean_squared_logarithmic_error: 7.9362e-04 - val_r_square_final: 2407908.1328 - val_pearson_r: -7.9965e-04 - val_mre: 32172.7728\n",
      "Epoch 23/70\n",
      "215999/215999 [==============================] - 58s 269us/step - loss: 0.0038 - mean_squared_error: 0.0038 - mean_absolute_error: 0.0304 - mean_absolute_percentage_error: 544.6244 - mean_squared_logarithmic_error: 0.0021 - r_square_final: 540.3624 - pearson_r: 0.0070 - mre: inf - val_loss: 9.6304e-04 - val_mean_squared_error: 9.6304e-04 - val_mean_absolute_error: 0.0256 - val_mean_absolute_percentage_error: 31.8083 - val_mean_squared_logarithmic_error: 7.9653e-04 - val_r_square_final: 2423452.2436 - val_pearson_r: -0.0053 - val_mre: 32258.5030\n",
      "Epoch 24/70\n",
      "215999/215999 [==============================] - 58s 271us/step - loss: 0.0038 - mean_squared_error: 0.0038 - mean_absolute_error: 0.0304 - mean_absolute_percentage_error: 540.3512 - mean_squared_logarithmic_error: 0.0021 - r_square_final: 511.9903 - pearson_r: 0.0086 - mre: inf - val_loss: 9.6392e-04 - val_mean_squared_error: 9.6392e-04 - val_mean_absolute_error: 0.0256 - val_mean_absolute_percentage_error: 31.8335 - val_mean_squared_logarithmic_error: 7.9726e-04 - val_r_square_final: 2367216.8047 - val_pearson_r: -0.0078 - val_mre: 32284.6509\n",
      "Epoch 25/70\n",
      "215999/215999 [==============================] - 57s 262us/step - loss: 0.0038 - mean_squared_error: 0.0038 - mean_absolute_error: 0.0304 - mean_absolute_percentage_error: 549.7282 - mean_squared_logarithmic_error: 0.0021 - r_square_final: 30166.5742 - pearson_r: 0.0089 - mre: inf - val_loss: 9.6174e-04 - val_mean_squared_error: 9.6174e-04 - val_mean_absolute_error: 0.0256 - val_mean_absolute_percentage_error: 31.7784 - val_mean_squared_logarithmic_error: 7.9542e-04 - val_r_square_final: 2447792.6166 - val_pearson_r: -0.0054 - val_mre: 32228.4914\n",
      "Epoch 26/70\n",
      "215999/215999 [==============================] - 56s 258us/step - loss: 0.0038 - mean_squared_error: 0.0038 - mean_absolute_error: 0.0304 - mean_absolute_percentage_error: 553.8887 - mean_squared_logarithmic_error: 0.0021 - r_square_final: 7920.7027 - pearson_r: 0.0071 - mre: inf - val_loss: 9.6170e-04 - val_mean_squared_error: 9.6170e-04 - val_mean_absolute_error: 0.0256 - val_mean_absolute_percentage_error: 31.7787 - val_mean_squared_logarithmic_error: 7.9542e-04 - val_r_square_final: 2452934.9499 - val_pearson_r: -0.0019 - val_mre: 32228.9889\n",
      "Epoch 27/70\n",
      "215999/215999 [==============================] - 58s 270us/step - loss: 0.0038 - mean_squared_error: 0.0038 - mean_absolute_error: 0.0304 - mean_absolute_percentage_error: 531.1271 - mean_squared_logarithmic_error: 0.0021 - r_square_final: 813886.9648 - pearson_r: 0.0052 - mre: inf - val_loss: 9.6457e-04 - val_mean_squared_error: 9.6457e-04 - val_mean_absolute_error: 0.0256 - val_mean_absolute_percentage_error: 31.8738 - val_mean_squared_logarithmic_error: 7.9786e-04 - val_r_square_final: 2432638.8712 - val_pearson_r: 0.0020 - val_mre: 32325.5123\n",
      "Epoch 28/70\n",
      "215999/215999 [==============================] - 59s 272us/step - loss: 0.0038 - mean_squared_error: 0.0038 - mean_absolute_error: 0.0304 - mean_absolute_percentage_error: 527.9428 - mean_squared_logarithmic_error: 0.0021 - r_square_final: 9097.1461 - pearson_r: 0.0092 - mre: inf - val_loss: 9.5860e-04 - val_mean_squared_error: 9.5860e-04 - val_mean_absolute_error: 0.0255 - val_mean_absolute_percentage_error: 31.6963 - val_mean_squared_logarithmic_error: 7.9279e-04 - val_r_square_final: 2474743.6166 - val_pearson_r: -0.0031 - val_mre: 32146.0110\n",
      "Epoch 29/70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "215999/215999 [==============================] - 57s 266us/step - loss: 0.0038 - mean_squared_error: 0.0038 - mean_absolute_error: 0.0304 - mean_absolute_percentage_error: 559.5720 - mean_squared_logarithmic_error: 0.0021 - r_square_final: 519.1628 - pearson_r: 0.0103 - mre: inf - val_loss: 9.6495e-04 - val_mean_squared_error: 9.6495e-04 - val_mean_absolute_error: 0.0256 - val_mean_absolute_percentage_error: 31.8880 - val_mean_squared_logarithmic_error: 7.9819e-04 - val_r_square_final: 2495158.2088 - val_pearson_r: -5.4146e-04 - val_mre: 32340.6457\n",
      "Epoch 30/70\n",
      "215999/215999 [==============================] - 59s 273us/step - loss: 0.0038 - mean_squared_error: 0.0038 - mean_absolute_error: 0.0304 - mean_absolute_percentage_error: 564.6437 - mean_squared_logarithmic_error: 0.0021 - r_square_final: 2912182.8517 - pearson_r: 0.0107 - mre: inf - val_loss: 9.6046e-04 - val_mean_squared_error: 9.6046e-04 - val_mean_absolute_error: 0.0255 - val_mean_absolute_percentage_error: 31.7579 - val_mean_squared_logarithmic_error: 7.9439e-04 - val_r_square_final: 2428049.7128 - val_pearson_r: -0.0033 - val_mre: 32209.1441\n",
      "Epoch 31/70\n",
      "215999/215999 [==============================] - 58s 271us/step - loss: 0.0038 - mean_squared_error: 0.0038 - mean_absolute_error: 0.0304 - mean_absolute_percentage_error: 537.4772 - mean_squared_logarithmic_error: 0.0021 - r_square_final: 1260.7721 - pearson_r: 0.0095 - mre: inf - val_loss: 9.5422e-04 - val_mean_squared_error: 9.5422e-04 - val_mean_absolute_error: 0.0255 - val_mean_absolute_percentage_error: 31.5768 - val_mean_squared_logarithmic_error: 7.8907e-04 - val_r_square_final: 2390487.7792 - val_pearson_r: -0.0024 - val_mre: 32023.7789\n",
      "Epoch 32/70\n",
      "215999/215999 [==============================] - 58s 268us/step - loss: 0.0038 - mean_squared_error: 0.0038 - mean_absolute_error: 0.0304 - mean_absolute_percentage_error: 559.2023 - mean_squared_logarithmic_error: 0.0021 - r_square_final: 9704.4396 - pearson_r: 0.0088 - mre: inf - val_loss: 9.5402e-04 - val_mean_squared_error: 9.5402e-04 - val_mean_absolute_error: 0.0255 - val_mean_absolute_percentage_error: 31.5816 - val_mean_squared_logarithmic_error: 7.8892e-04 - val_r_square_final: 2401865.4417 - val_pearson_r: -0.0017 - val_mre: 32028.3166\n",
      "Epoch 33/70\n",
      "215999/215999 [==============================] - 57s 264us/step - loss: 0.0037 - mean_squared_error: 0.0037 - mean_absolute_error: 0.0304 - mean_absolute_percentage_error: 541.4709 - mean_squared_logarithmic_error: 0.0021 - r_square_final: 547.3342 - pearson_r: 0.0111 - mre: inf - val_loss: 9.6574e-04 - val_mean_squared_error: 9.6574e-04 - val_mean_absolute_error: 0.0256 - val_mean_absolute_percentage_error: 31.9092 - val_mean_squared_logarithmic_error: 7.9884e-04 - val_r_square_final: 2576766.1094 - val_pearson_r: -0.0022 - val_mre: 32362.1202\n",
      "Epoch 34/70\n",
      "215999/215999 [==============================] - 57s 262us/step - loss: 0.0037 - mean_squared_error: 0.0037 - mean_absolute_error: 0.0304 - mean_absolute_percentage_error: 563.4443 - mean_squared_logarithmic_error: 0.0021 - r_square_final: 8128.6420 - pearson_r: 0.0122 - mre: inf - val_loss: 9.5691e-04 - val_mean_squared_error: 9.5691e-04 - val_mean_absolute_error: 0.0255 - val_mean_absolute_percentage_error: 31.6863 - val_mean_squared_logarithmic_error: 7.9141e-04 - val_r_square_final: 2356610.4230 - val_pearson_r: 8.8306e-05 - val_mre: 32135.8968\n",
      "Epoch 35/70\n",
      "215999/215999 [==============================] - 57s 265us/step - loss: 0.0038 - mean_squared_error: 0.0038 - mean_absolute_error: 0.0304 - mean_absolute_percentage_error: 559.1060 - mean_squared_logarithmic_error: 0.0021 - r_square_final: 304.6808 - pearson_r: 0.0081 - mre: inf - val_loss: 9.5657e-04 - val_mean_squared_error: 9.5657e-04 - val_mean_absolute_error: 0.0255 - val_mean_absolute_percentage_error: 31.6680 - val_mean_squared_logarithmic_error: 7.9110e-04 - val_r_square_final: 2494843.3750 - val_pearson_r: 0.0017 - val_mre: 32117.6707\n",
      "Epoch 36/70\n",
      "215999/215999 [==============================] - 57s 265us/step - loss: 0.0038 - mean_squared_error: 0.0038 - mean_absolute_error: 0.0304 - mean_absolute_percentage_error: 522.6686 - mean_squared_logarithmic_error: 0.0021 - r_square_final: 1559.2173 - pearson_r: 0.0067 - mre: inf - val_loss: 9.6607e-04 - val_mean_squared_error: 9.6607e-04 - val_mean_absolute_error: 0.0256 - val_mean_absolute_percentage_error: 31.9267 - val_mean_squared_logarithmic_error: 7.9914e-04 - val_r_square_final: 2580704.8385 - val_pearson_r: 0.0041 - val_mre: 32380.8979\n",
      "Epoch 37/70\n",
      "215999/215999 [==============================] - 54s 252us/step - loss: 0.0037 - mean_squared_error: 0.0037 - mean_absolute_error: 0.0304 - mean_absolute_percentage_error: 535.3946 - mean_squared_logarithmic_error: 0.0021 - r_square_final: 326.3938 - pearson_r: 0.0109 - mre: inf - val_loss: 9.5700e-04 - val_mean_squared_error: 9.5700e-04 - val_mean_absolute_error: 0.0255 - val_mean_absolute_percentage_error: 31.6794 - val_mean_squared_logarithmic_error: 7.9147e-04 - val_r_square_final: 2578764.2995 - val_pearson_r: 0.0108 - val_mre: 32130.6332\n",
      "Epoch 38/70\n",
      "215999/215999 [==============================] - 48s 223us/step - loss: 0.0038 - mean_squared_error: 0.0038 - mean_absolute_error: 0.0304 - mean_absolute_percentage_error: 561.3082 - mean_squared_logarithmic_error: 0.0021 - r_square_final: 5254.1377 - pearson_r: 0.0087 - mre: inf - val_loss: 9.5949e-04 - val_mean_squared_error: 9.5949e-04 - val_mean_absolute_error: 0.0255 - val_mean_absolute_percentage_error: 31.7652 - val_mean_squared_logarithmic_error: 7.9362e-04 - val_r_square_final: 2431287.8128 - val_pearson_r: 0.0096 - val_mre: 32217.0932\n",
      "Epoch 39/70\n",
      "215999/215999 [==============================] - 49s 226us/step - loss: 0.0038 - mean_squared_error: 0.0038 - mean_absolute_error: 0.0304 - mean_absolute_percentage_error: 536.6096 - mean_squared_logarithmic_error: 0.0021 - r_square_final: 18437285.3846 - pearson_r: 0.0100 - mre: inf - val_loss: 9.5795e-04 - val_mean_squared_error: 9.5795e-04 - val_mean_absolute_error: 0.0255 - val_mean_absolute_percentage_error: 31.7312 - val_mean_squared_logarithmic_error: 7.9232e-04 - val_r_square_final: 2445653.5635 - val_pearson_r: 0.0115 - val_mre: 32181.9016\n",
      "Epoch 40/70\n",
      "215999/215999 [==============================] - 58s 267us/step - loss: 0.0037 - mean_squared_error: 0.0037 - mean_absolute_error: 0.0304 - mean_absolute_percentage_error: 540.9007 - mean_squared_logarithmic_error: 0.0021 - r_square_final: 239.0780 - pearson_r: 0.0097 - mre: inf - val_loss: 9.5585e-04 - val_mean_squared_error: 9.5585e-04 - val_mean_absolute_error: 0.0255 - val_mean_absolute_percentage_error: 31.6586 - val_mean_squared_logarithmic_error: 7.9053e-04 - val_r_square_final: 2337335.7222 - val_pearson_r: 0.0076 - val_mre: 32108.2525\n",
      "Epoch 41/70\n",
      "215999/215999 [==============================] - 61s 282us/step - loss: 0.0038 - mean_squared_error: 0.0038 - mean_absolute_error: 0.0304 - mean_absolute_percentage_error: 555.3173 - mean_squared_logarithmic_error: 0.0021 - r_square_final: 1002.4892 - pearson_r: 0.0082 - mre: inf - val_loss: 9.5876e-04 - val_mean_squared_error: 9.5876e-04 - val_mean_absolute_error: 0.0255 - val_mean_absolute_percentage_error: 31.7405 - val_mean_squared_logarithmic_error: 7.9300e-04 - val_r_square_final: 2356496.9337 - val_pearson_r: -1.6355e-04 - val_mre: 32189.9371\n",
      "Epoch 42/70\n",
      "215999/215999 [==============================] - 61s 284us/step - loss: 0.0037 - mean_squared_error: 0.0037 - mean_absolute_error: 0.0304 - mean_absolute_percentage_error: 546.9106 - mean_squared_logarithmic_error: 0.0021 - r_square_final: 873.0137 - pearson_r: 0.0098 - mre: inf - val_loss: 9.6875e-04 - val_mean_squared_error: 9.6875e-04 - val_mean_absolute_error: 0.0257 - val_mean_absolute_percentage_error: 32.0189 - val_mean_squared_logarithmic_error: 8.0144e-04 - val_r_square_final: 2559364.7939 - val_pearson_r: 0.0152 - val_mre: 32473.0127\n",
      "Epoch 43/70\n",
      "215999/215999 [==============================] - 61s 281us/step - loss: 0.0038 - mean_squared_error: 0.0038 - mean_absolute_error: 0.0304 - mean_absolute_percentage_error: 546.2318 - mean_squared_logarithmic_error: 0.0021 - r_square_final: 5813.1561 - pearson_r: 0.0086 - mre: inf - val_loss: 9.5982e-04 - val_mean_squared_error: 9.5982e-04 - val_mean_absolute_error: 0.0255 - val_mean_absolute_percentage_error: 31.7591 - val_mean_squared_logarithmic_error: 7.9385e-04 - val_r_square_final: 2496131.9541 - val_pearson_r: -1.2910e-05 - val_mre: 32209.6741\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44/70\n",
      "215999/215999 [==============================] - 62s 285us/step - loss: 0.0038 - mean_squared_error: 0.0038 - mean_absolute_error: 0.0304 - mean_absolute_percentage_error: 535.9999 - mean_squared_logarithmic_error: 0.0021 - r_square_final: 361.9913 - pearson_r: 0.0073 - mre: inf - val_loss: 9.6875e-04 - val_mean_squared_error: 9.6875e-04 - val_mean_absolute_error: 0.0257 - val_mean_absolute_percentage_error: 32.0318 - val_mean_squared_logarithmic_error: 8.0146e-04 - val_r_square_final: 2382709.7445 - val_pearson_r: 0.0114 - val_mre: 32486.5286\n",
      "Epoch 45/70\n",
      "215999/215999 [==============================] - 61s 281us/step - loss: 0.0038 - mean_squared_error: 0.0038 - mean_absolute_error: 0.0304 - mean_absolute_percentage_error: 571.5855 - mean_squared_logarithmic_error: 0.0021 - r_square_final: 729.6203 - pearson_r: 0.0070 - mre: inf - val_loss: 9.4502e-04 - val_mean_squared_error: 9.4502e-04 - val_mean_absolute_error: 0.0253 - val_mean_absolute_percentage_error: 31.3588 - val_mean_squared_logarithmic_error: 7.8134e-04 - val_r_square_final: 2205264.9281 - val_pearson_r: 0.0043 - val_mre: 31803.7141\n",
      "Epoch 46/70\n",
      "215999/215999 [==============================] - 66s 307us/step - loss: 0.0037 - mean_squared_error: 0.0037 - mean_absolute_error: 0.0304 - mean_absolute_percentage_error: 547.2822 - mean_squared_logarithmic_error: 0.0021 - r_square_final: 1788.3796 - pearson_r: 0.0103 - mre: inf - val_loss: 9.5218e-04 - val_mean_squared_error: 9.5218e-04 - val_mean_absolute_error: 0.0254 - val_mean_absolute_percentage_error: 31.5711 - val_mean_squared_logarithmic_error: 7.8745e-04 - val_r_square_final: 2399212.5190 - val_pearson_r: 0.0095 - val_mre: 32017.9333\n",
      "Epoch 47/70\n",
      "215999/215999 [==============================] - 64s 296us/step - loss: 0.0038 - mean_squared_error: 0.0038 - mean_absolute_error: 0.0304 - mean_absolute_percentage_error: 534.0702 - mean_squared_logarithmic_error: 0.0021 - r_square_final: 2526.5527 - pearson_r: 0.0079 - mre: inf - val_loss: 9.4892e-04 - val_mean_squared_error: 9.4892e-04 - val_mean_absolute_error: 0.0254 - val_mean_absolute_percentage_error: 31.4700 - val_mean_squared_logarithmic_error: 7.8467e-04 - val_r_square_final: 2292025.9501 - val_pearson_r: 0.0042 - val_mre: 31916.1011\n",
      "Epoch 48/70\n",
      "215999/215999 [==============================] - 61s 282us/step - loss: 0.0037 - mean_squared_error: 0.0037 - mean_absolute_error: 0.0304 - mean_absolute_percentage_error: 551.4277 - mean_squared_logarithmic_error: 0.0021 - r_square_final: 1674.8885 - pearson_r: 0.0088 - mre: inf - val_loss: 9.5572e-04 - val_mean_squared_error: 9.5572e-04 - val_mean_absolute_error: 0.0255 - val_mean_absolute_percentage_error: 31.6596 - val_mean_squared_logarithmic_error: 7.9041e-04 - val_r_square_final: 2073397.6754 - val_pearson_r: -3.0256e-06 - val_mre: 32108.1960\n",
      "Epoch 49/70\n",
      "215999/215999 [==============================] - 60s 279us/step - loss: 0.0037 - mean_squared_error: 0.0037 - mean_absolute_error: 0.0304 - mean_absolute_percentage_error: 529.3282 - mean_squared_logarithmic_error: 0.0021 - r_square_final: 288.6231 - pearson_r: 0.0088 - mre: inf - val_loss: 9.5992e-04 - val_mean_squared_error: 9.5992e-04 - val_mean_absolute_error: 0.0255 - val_mean_absolute_percentage_error: 31.7744 - val_mean_squared_logarithmic_error: 7.9398e-04 - val_r_square_final: 2410255.5180 - val_pearson_r: -0.0056 - val_mre: 32225.5920\n",
      "Epoch 50/70\n",
      "215999/215999 [==============================] - 61s 282us/step - loss: 0.0037 - mean_squared_error: 0.0037 - mean_absolute_error: 0.0304 - mean_absolute_percentage_error: 557.1547 - mean_squared_logarithmic_error: 0.0021 - r_square_final: 425.5299 - pearson_r: 0.0088 - mre: inf - val_loss: 9.6463e-04 - val_mean_squared_error: 9.6463e-04 - val_mean_absolute_error: 0.0256 - val_mean_absolute_percentage_error: 31.8982 - val_mean_squared_logarithmic_error: 7.9792e-04 - val_r_square_final: 2694790.3886 - val_pearson_r: 0.0059 - val_mre: 32350.7491\n",
      "Epoch 51/70\n",
      "215999/215999 [==============================] - 61s 280us/step - loss: 0.0037 - mean_squared_error: 0.0037 - mean_absolute_error: 0.0304 - mean_absolute_percentage_error: 535.8716 - mean_squared_logarithmic_error: 0.0021 - r_square_final: 1075.0385 - pearson_r: 0.0067 - mre: inf - val_loss: 9.6770e-04 - val_mean_squared_error: 9.6770e-04 - val_mean_absolute_error: 0.0257 - val_mean_absolute_percentage_error: 32.0092 - val_mean_squared_logarithmic_error: 8.0058e-04 - val_r_square_final: 2585367.4047 - val_pearson_r: 0.0112 - val_mre: 32462.8222\n",
      "Epoch 52/70\n",
      "215999/215999 [==============================] - 61s 283us/step - loss: 0.0037 - mean_squared_error: 0.0037 - mean_absolute_error: 0.0304 - mean_absolute_percentage_error: 530.1955 - mean_squared_logarithmic_error: 0.0021 - r_square_final: 293.0696 - pearson_r: 0.0070 - mre: inf - val_loss: 9.6118e-04 - val_mean_squared_error: 9.6118e-04 - val_mean_absolute_error: 0.0256 - val_mean_absolute_percentage_error: 31.8173 - val_mean_squared_logarithmic_error: 7.9505e-04 - val_r_square_final: 2502083.6967 - val_pearson_r: -8.9766e-04 - val_mre: 32268.8661\n",
      "Epoch 53/70\n",
      "215999/215999 [==============================] - 60s 277us/step - loss: 0.0037 - mean_squared_error: 0.0037 - mean_absolute_error: 0.0304 - mean_absolute_percentage_error: 560.9570 - mean_squared_logarithmic_error: 0.0021 - r_square_final: 2384.0913 - pearson_r: 0.0058 - mre: inf - val_loss: 9.6633e-04 - val_mean_squared_error: 9.6633e-04 - val_mean_absolute_error: 0.0256 - val_mean_absolute_percentage_error: 31.9389 - val_mean_squared_logarithmic_error: 7.9935e-04 - val_r_square_final: 2417251.9639 - val_pearson_r: 0.0017 - val_mre: 32391.1562\n",
      "Epoch 54/70\n",
      "215999/215999 [==============================] - 59s 273us/step - loss: 0.0037 - mean_squared_error: 0.0037 - mean_absolute_error: 0.0304 - mean_absolute_percentage_error: 521.8631 - mean_squared_logarithmic_error: 0.0021 - r_square_final: 4279.5186 - pearson_r: 0.0103 - mre: inf - val_loss: 9.5364e-04 - val_mean_squared_error: 9.5364e-04 - val_mean_absolute_error: 0.0255 - val_mean_absolute_percentage_error: 31.6171 - val_mean_squared_logarithmic_error: 7.8869e-04 - val_r_square_final: 2304762.7584 - val_pearson_r: 0.0055 - val_mre: 32064.2714\n",
      "Epoch 55/70\n",
      "215999/215999 [==============================] - 61s 280us/step - loss: 0.0038 - mean_squared_error: 0.0038 - mean_absolute_error: 0.0304 - mean_absolute_percentage_error: 512.8026 - mean_squared_logarithmic_error: 0.0021 - r_square_final: 2759.2035 - pearson_r: 0.0085 - mre: inf - val_loss: 9.6007e-04 - val_mean_squared_error: 9.6007e-04 - val_mean_absolute_error: 0.0256 - val_mean_absolute_percentage_error: 31.7989 - val_mean_squared_logarithmic_error: 7.9412e-04 - val_r_square_final: 2551661.2062 - val_pearson_r: 0.0020 - val_mre: 32249.8760\n",
      "Epoch 56/70\n",
      "215999/215999 [==============================] - 61s 281us/step - loss: 0.0037 - mean_squared_error: 0.0037 - mean_absolute_error: 0.0304 - mean_absolute_percentage_error: 546.7908 - mean_squared_logarithmic_error: 0.0021 - r_square_final: 27220.1435 - pearson_r: 0.0060 - mre: inf - val_loss: 9.5508e-04 - val_mean_squared_error: 9.5508e-04 - val_mean_absolute_error: 0.0255 - val_mean_absolute_percentage_error: 31.6557 - val_mean_squared_logarithmic_error: 7.8989e-04 - val_r_square_final: 3266967.2404 - val_pearson_r: -3.0164e-04 - val_mre: 32103.5784\n",
      "Epoch 57/70\n",
      "215999/215999 [==============================] - 60s 278us/step - loss: 0.0037 - mean_squared_error: 0.0037 - mean_absolute_error: 0.0303 - mean_absolute_percentage_error: 528.1701 - mean_squared_logarithmic_error: 0.0021 - r_square_final: 7805.5092 - pearson_r: 0.0095 - mre: inf - val_loss: 9.6467e-04 - val_mean_squared_error: 9.6467e-04 - val_mean_absolute_error: 0.0256 - val_mean_absolute_percentage_error: 31.9089 - val_mean_squared_logarithmic_error: 7.9799e-04 - val_r_square_final: 2380065.2835 - val_pearson_r: 0.0024 - val_mre: 32360.3410\n",
      "Epoch 58/70\n",
      "215999/215999 [==============================] - 60s 276us/step - loss: 0.0037 - mean_squared_error: 0.0037 - mean_absolute_error: 0.0304 - mean_absolute_percentage_error: 555.2747 - mean_squared_logarithmic_error: 0.0021 - r_square_final: 30692.8635 - pearson_r: 0.0060 - mre: inf - val_loss: 9.6045e-04 - val_mean_squared_error: 9.6045e-04 - val_mean_absolute_error: 0.0256 - val_mean_absolute_percentage_error: 31.8036 - val_mean_squared_logarithmic_error: 7.9443e-04 - val_r_square_final: 2706611.3290 - val_pearson_r: 0.0039 - val_mre: 32252.9572\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/70\n",
      "215999/215999 [==============================] - 60s 279us/step - loss: 0.0037 - mean_squared_error: 0.0037 - mean_absolute_error: 0.0304 - mean_absolute_percentage_error: 509.2613 - mean_squared_logarithmic_error: 0.0021 - r_square_final: 2656.9021 - pearson_r: 0.0054 - mre: inf - val_loss: 9.5811e-04 - val_mean_squared_error: 9.5811e-04 - val_mean_absolute_error: 0.0255 - val_mean_absolute_percentage_error: 31.7451 - val_mean_squared_logarithmic_error: 7.9246e-04 - val_r_square_final: 2488896.3661 - val_pearson_r: 0.0014 - val_mre: 32195.5282\n",
      "Epoch 60/70\n",
      "215999/215999 [==============================] - 60s 279us/step - loss: 0.0037 - mean_squared_error: 0.0037 - mean_absolute_error: 0.0304 - mean_absolute_percentage_error: 564.0049 - mean_squared_logarithmic_error: 0.0021 - r_square_final: 69.7779 - pearson_r: 0.0074 - mre: inf - val_loss: 9.5599e-04 - val_mean_squared_error: 9.5599e-04 - val_mean_absolute_error: 0.0255 - val_mean_absolute_percentage_error: 31.6676 - val_mean_squared_logarithmic_error: 7.9065e-04 - val_r_square_final: 2331318.8221 - val_pearson_r: 0.0097 - val_mre: 32117.5904\n",
      "Epoch 61/70\n",
      "215999/215999 [==============================] - 60s 279us/step - loss: 0.0038 - mean_squared_error: 0.0038 - mean_absolute_error: 0.0304 - mean_absolute_percentage_error: 550.2511 - mean_squared_logarithmic_error: 0.0021 - r_square_final: 2030.9517 - pearson_r: 0.0064 - mre: inf - val_loss: 9.5595e-04 - val_mean_squared_error: 9.5595e-04 - val_mean_absolute_error: 0.0255 - val_mean_absolute_percentage_error: 31.6268 - val_mean_squared_logarithmic_error: 7.9052e-04 - val_r_square_final: 6500880.3831 - val_pearson_r: 5.8470e-04 - val_mre: 32075.2122\n",
      "Epoch 62/70\n",
      "215999/215999 [==============================] - 59s 272us/step - loss: 0.0038 - mean_squared_error: 0.0038 - mean_absolute_error: 0.0304 - mean_absolute_percentage_error: 528.9749 - mean_squared_logarithmic_error: 0.0021 - r_square_final: 11068.5393 - pearson_r: 0.0010 - mre: inf - val_loss: 9.7258e-04 - val_mean_squared_error: 9.7258e-04 - val_mean_absolute_error: 0.0257 - val_mean_absolute_percentage_error: 32.0962 - val_mean_squared_logarithmic_error: 8.0459e-04 - val_r_square_final: 2339201.6953 - val_pearson_r: 0.0142 - val_mre: 32552.0695\n",
      "Epoch 63/70\n",
      "215999/215999 [==============================] - 61s 281us/step - loss: 0.0038 - mean_squared_error: 0.0038 - mean_absolute_error: 0.0304 - mean_absolute_percentage_error: 555.5984 - mean_squared_logarithmic_error: 0.0021 - r_square_final: 18032.1182 - pearson_r: 0.0034 - mre: inf - val_loss: 9.3843e-04 - val_mean_squared_error: 9.3843e-04 - val_mean_absolute_error: 0.0252 - val_mean_absolute_percentage_error: 31.1472 - val_mean_squared_logarithmic_error: 7.7570e-04 - val_r_square_final: 1435155.4611 - val_pearson_r: 0.0047 - val_mre: 31585.5834\n",
      "Epoch 64/70\n",
      "215999/215999 [==============================] - 60s 279us/step - loss: 0.0038 - mean_squared_error: 0.0038 - mean_absolute_error: 0.0304 - mean_absolute_percentage_error: 556.7255 - mean_squared_logarithmic_error: 0.0021 - r_square_final: 3724.5800 - pearson_r: 0.0050 - mre: inf - val_loss: 9.5102e-04 - val_mean_squared_error: 9.5102e-04 - val_mean_absolute_error: 0.0254 - val_mean_absolute_percentage_error: 31.5466 - val_mean_squared_logarithmic_error: 7.8645e-04 - val_r_square_final: 2216069.2380 - val_pearson_r: 0.0083 - val_mre: 31994.9095\n",
      "Epoch 65/70\n",
      "215999/215999 [==============================] - 61s 280us/step - loss: 0.0038 - mean_squared_error: 0.0038 - mean_absolute_error: 0.0304 - mean_absolute_percentage_error: 549.7141 - mean_squared_logarithmic_error: 0.0021 - r_square_final: 788.3607 - pearson_r: 0.0014 - mre: inf - val_loss: 9.6157e-04 - val_mean_squared_error: 9.6157e-04 - val_mean_absolute_error: 0.0256 - val_mean_absolute_percentage_error: 31.7877 - val_mean_squared_logarithmic_error: 7.9529e-04 - val_r_square_final: 2284153.0741 - val_pearson_r: -0.0033 - val_mre: 32237.2326\n",
      "Epoch 66/70\n",
      "215999/215999 [==============================] - 54s 252us/step - loss: 0.0037 - mean_squared_error: 0.0037 - mean_absolute_error: 0.0304 - mean_absolute_percentage_error: 553.2422 - mean_squared_logarithmic_error: 0.0021 - r_square_final: 359.3075 - pearson_r: 0.0084 - mre: inf - val_loss: 9.5286e-04 - val_mean_squared_error: 9.5286e-04 - val_mean_absolute_error: 0.0254 - val_mean_absolute_percentage_error: 31.5855 - val_mean_squared_logarithmic_error: 7.8799e-04 - val_r_square_final: 2339691.1155 - val_pearson_r: 0.0037 - val_mre: 32032.1632\n",
      "Epoch 67/70\n",
      "215999/215999 [==============================] - 52s 241us/step - loss: 0.0038 - mean_squared_error: 0.0038 - mean_absolute_error: 0.0304 - mean_absolute_percentage_error: 553.6169 - mean_squared_logarithmic_error: 0.0021 - r_square_final: 31505.2777 - pearson_r: 0.0031 - mre: inf - val_loss: 9.6865e-04 - val_mean_squared_error: 9.6865e-04 - val_mean_absolute_error: 0.0257 - val_mean_absolute_percentage_error: 32.0192 - val_mean_squared_logarithmic_error: 8.0136e-04 - val_r_square_final: 2406132.7858 - val_pearson_r: 0.0030 - val_mre: 32472.5158\n",
      "Epoch 68/70\n",
      "215999/215999 [==============================] - 57s 265us/step - loss: 0.0038 - mean_squared_error: 0.0038 - mean_absolute_error: 0.0304 - mean_absolute_percentage_error: 522.1540 - mean_squared_logarithmic_error: 0.0021 - r_square_final: 47310.4499 - pearson_r: 0.0038 - mre: inf - val_loss: 9.5801e-04 - val_mean_squared_error: 9.5801e-04 - val_mean_absolute_error: 0.0255 - val_mean_absolute_percentage_error: 31.7489 - val_mean_squared_logarithmic_error: 7.9242e-04 - val_r_square_final: 2815901.2621 - val_pearson_r: 0.0195 - val_mre: 32199.0479\n",
      "Epoch 69/70\n",
      "215999/215999 [==============================] - 59s 274us/step - loss: 0.0038 - mean_squared_error: 0.0038 - mean_absolute_error: 0.0304 - mean_absolute_percentage_error: 547.1249 - mean_squared_logarithmic_error: 0.0021 - r_square_final: 34823.3697 - pearson_r: 0.0054 - mre: inf - val_loss: 9.7062e-04 - val_mean_squared_error: 9.7062e-04 - val_mean_absolute_error: 0.0257 - val_mean_absolute_percentage_error: 32.0670 - val_mean_squared_logarithmic_error: 8.0300e-04 - val_r_square_final: 2788425.7520 - val_pearson_r: 0.0044 - val_mre: 32520.6786\n",
      "Epoch 70/70\n",
      "215999/215999 [==============================] - 58s 269us/step - loss: 0.0038 - mean_squared_error: 0.0038 - mean_absolute_error: 0.0304 - mean_absolute_percentage_error: 544.5544 - mean_squared_logarithmic_error: 0.0021 - r_square_final: 13495.0334 - pearson_r: 0.0020 - mre: inf - val_loss: 9.5695e-04 - val_mean_squared_error: 9.5695e-04 - val_mean_absolute_error: 0.0255 - val_mean_absolute_percentage_error: 31.6981 - val_mean_squared_logarithmic_error: 7.9146e-04 - val_r_square_final: 2418279.0947 - val_pearson_r: 0.0014 - val_mre: 32147.9902\n"
     ]
    }
   ],
   "source": [
    "keras.backend.get_session().run(tf.global_variables_initializer())\n",
    "\n",
    "\n",
    "his=model.fit(\n",
    "    X,\n",
    "    y,\n",
    "    \n",
    "    validation_split=0.1,\n",
    "    epochs=70,\n",
    "    batch_size=1024,\n",
    "    \n",
    "    shuffle=True,\n",
    "    verbose=1,\n",
    "    \n",
    "    \n",
    "    callbacks=callbacks_list\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate predictions\n",
    "\n",
    "test_X = X\n",
    "#actual = y\n",
    "\n",
    "# from keras.models import load_model\n",
    "\n",
    "# model = load_model('model.h5')\n",
    "predictions = model.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# round predictions\n",
    "B = []\n",
    "for x in predictions:\n",
    "    for i in x:\n",
    "        B.append(i)\n",
    "        \n",
    "B = B[1:239999]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual = y[1:239999]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum, sum2 = float(0), float(0)\n",
    "max, mre, res, abres = float(0), float(0), float(0), float(0)\n",
    "\n",
    "zipped = zip(actual, B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual\t\tPredicted\t MRE\t\tRes. Error\tAbs. Res. Error\n"
     ]
    }
   ],
   "source": [
    "print(\"Actual\\t\\tPredicted\\t MRE\\t\\tRes. Error\\tAbs. Res. Error\")\n",
    "for i, j in zipped:\n",
    "    mre = float(abs(float(i) - float(j))) / float(i)\n",
    "    res = float(i) - float(j)\n",
    "    abres = float(abs(res))\n",
    "    sum = sum + mre\n",
    "    sum2 = sum2 + res\n",
    "    if (abs(float(i) - float(j)) / float(i) > max):\n",
    "        max = float(abs(float(i) - float(j))) / float(i)\n",
    "    stringI = '{:.4f}'.format(float(i))\n",
    "    stringJ = '{:.4f}'.format(float(j))\n",
    "    #print (stringI, \"\\t\\t\", stringJ, \"\\t\", '{:.4f}'.format(mre), \"\\t\", '{:.4f}'.format(res), \"\\t\", '{:.4f}'.format(abres))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-958f268b7623>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mabsolute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0my_predict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Mean Absolute Error      \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmean_absolute_error_byself\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mactual\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mB\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Mean Squared Error       \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmean_squared_error_byself\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mactual\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mB\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Root Mean Square Error : \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mroot_mean_squared_error_byself\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mactual\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mB\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-20-958f268b7623>\u001b[0m in \u001b[0;36mmean_absolute_error_byself\u001b[1;34m(y_true, y_predict)\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[1;34m\"\"\"计算y_true和y_predict之间的MAE\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[1;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_predict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m         \u001b[1;34m\"the size of y_true must be equal to be the size of y_predict\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mabsolute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0my_predict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Mean Absolute Error      \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmean_absolute_error_byself\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mactual\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mB\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def mean_squared_error_byself(y_true,y_predict):\n",
    "    assert len(y_true) == len(y_predict), \\\n",
    "        \"the size of y_true must be equal to be the size of y_predict\"\n",
    "    return np.sum((y_true - y_predict) ** 2 ) / len(y_true)\n",
    "\n",
    "def root_mean_squared_error_byself(y_true,y_predict):\n",
    "    \"\"\"计算y_true和y_predict之间的RMES\"\"\"\n",
    "    assert len(y_true) == len(y_predict), \\\n",
    "        \"the size of y_true must be equal to be the size of y_predict\"\n",
    "    return math.sqrt(np.sum((y_true - y_predict) ** 2 ) / len(y_true))\n",
    "\n",
    "def mean_absolute_error_byself(y_true,y_predict):\n",
    "    \"\"\"计算y_true和y_predict之间的MAE\"\"\"\n",
    "    assert len(y_true) == len(y_predict), \\\n",
    "        \"the size of y_true must be equal to be the size of y_predict\"\n",
    "    return np.sum(np.absolute(y_true - y_predict)) / len(y_true)\n",
    "\n",
    "print(\"Mean Absolute Error      \", mean_absolute_error_byself(np.array(actual, dtype = float) , np.array(B, dtype = float)))\n",
    "print(\"Mean Squared Error       \", mean_squared_error_byself(np.array(actual, dtype = float) , np.array(B, dtype = float)))\n",
    "print(\"Root Mean Square Error : \", root_mean_squared_error_byself(np.array(actual, dtype = float) , np.array(B, dtype = float)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mean Magnitude of Relative Error (MMRE) :  0.0\n",
      "MaxMRE :                  0.0\n",
      "Explained Variance Score  -0.0005160613297856553\n",
      "Mean Absolute Error       0.029836204371257585\n",
      "Mean Squared Error        0.003469103991219168\n",
      "Median Absolute Error     0.02354980006980896\n",
      "R-Square Score            -0.0006859557688050355\n",
      "Root Mean Square Error :  0.0\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nMean Magnitude of Relative Error (MMRE) : \", sum / len(actual))\n",
    "print(\"MaxMRE :                 \", max)\n",
    "print(\"Explained Variance Score \", metrics.explained_variance_score(np.array(actual, dtype = float) , np.array(B, dtype = float)))\n",
    "print(\"Mean Absolute Error      \", metrics.mean_absolute_error(np.array(actual, dtype = float) , np.array(B, dtype = float)))\n",
    "print(\"Mean Squared Error       \", metrics.mean_squared_error(np.array(actual, dtype = float) , np.array(B, dtype = float)))\n",
    "print(\"Median Absolute Error    \", metrics.median_absolute_error(np.array(actual, dtype = float) , np.array(B, dtype = float)))\n",
    "print(\"R-Square Score           \", metrics.r2_score(np.array(actual, dtype = float) , np.array(B, dtype = float)))\n",
    "print(\"Root Mean Square Error : \", (sum2 / len(B)) ** (1 / 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
